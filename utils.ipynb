{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# utilså®‰æ’\n",
    "utilsä¸­é—´ä¼šåŒ…å«logging \\ scheduler \\ optimizer \\ evaluateä¹‹ç±»çš„å‡½æ•°ï¼Œå°±ä¸ªäººè€Œè¨€æˆ‘åœ¨å¯»æ‰¾å‡½æ•°åˆ†å‰²çš„ä¸€ä¸ªåº¦ã€‚å“ªäº›å‡½æ•°å¯ä»¥å½“æˆç‹¬ç«‹çš„æ¨¡å—åˆ†ç¦»å‡ºæ¥ã€‚\n",
    "\n",
    "## WeChat_challenge\n",
    "åœ¨å¾®ä¿¡æŒ‘æˆ˜èµ›ä¸­ä»–å°†setup_device \\ setup_seed å•ç‹¬åˆ†äº†å‡ºæ¥ï¼Œæˆ‘å…¶å®ä¸€ç›´æœ‰åœ¨æƒ³ï¼Œå°†setup_deviceå’Œsetup_seed åˆ†ç¦»å‡ºæ¥æ˜¯å¦å¤šä½™ï¼Œæš‚ä¸”è®°å½•ä¸€ä¸‹\n",
    "å…¶å®æˆ‘è§‰å¾—best_scoreçš„è¾“å‡ºæ‰æ˜¯æœ€é‡è¦çš„\n",
    "\n",
    "## setup_device(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def setup_device(args):\n",
    "    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    args.n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## setup_seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def setup_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def evaluate(predictions, labels):\n",
    "    # prediction and labels are all level-2 class ids\n",
    "\n",
    "    lv1_preds = [lv2id_to_lv1id(lv2id) for lv2id in predictions]\n",
    "    lv1_labels = [lv2id_to_lv1id(lv2id) for lv2id in labels]\n",
    "\n",
    "    lv2_f1_micro = f1_score(labels, predictions, average='micro')\n",
    "    lv2_f1_macro = f1_score(labels, predictions, average='macro')\n",
    "    lv1_f1_micro = f1_score(lv1_labels, lv1_preds, average='micro')\n",
    "    lv1_f1_macro = f1_score(lv1_labels, lv1_preds, average='macro')\n",
    "    mean_f1 = (lv2_f1_macro + lv1_f1_macro + lv1_f1_micro + lv2_f1_micro) / 4.0\n",
    "\n",
    "    eval_results = {'lv1_acc': accuracy_score(lv1_labels, lv1_preds),\n",
    "                    'lv2_acc': accuracy_score(labels, predictions),\n",
    "                    'lv1_f1_micro': lv1_f1_micro,\n",
    "                    'lv1_f1_macro': lv1_f1_macro,\n",
    "                    'lv2_f1_micro': lv2_f1_micro,\n",
    "                    'lv2_f1_macro': lv2_f1_macro,\n",
    "                    'mean_f1': mean_f1}\n",
    "\n",
    "    return eval_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## best score\n",
    "æˆ‘ä¸ªäººéå¸¸å–œæ¬¢è¿™ä¸ªè®¾å®šï¼Œä½†æ˜¯å®é™…ä¸Šåœ¨æ“ä½œä¸­è¿™ä¸ªæ˜¯é€šè¿‡è¿­ä»£äº†ä¸€å®šç¨‹åº¦çš„ä»£ç å,å†æ ¹æ®è¶…å‚æ•°æ¥è®¾ç½®çš„ã€‚\n",
    "å¯ä»¥å­¦ä¸€ä¸‹ï¼Œç„¶ååšäº†åˆæœŸè¯•éªŒåæ»¤æ‰ä¸æ»¡è¶³å‡†ç¡®ç‡çš„æ¨¡å‹ï¼ŒèŠ‚çœç©ºé—´"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if mean_f1 > best_score:\n",
    "    best_score = mean_f1\n",
    "    state_dict = model.module.state_dict() if args.device == 'cuda' else model.state_dict()\n",
    "    torch.save({'epoch': epoch, 'model_state_dict': state_dict, 'mean_f1': mean_f1},\n",
    "    f'{args.savedmodel_path}/model_epoch_{epoch}_mean_f1_{mean_f1}.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## unifiedprasing\n",
    "è¿™ç¯‡æ˜¯éå¸¸æ—©çš„semantic segmentationçš„æ–‡ç« ï¼Œæå‡ºUperNetç½‘ç»œç»“æ„ã€‚åœ¨utilsä¸­ä»–åŒ…å«äº†ä¸€å®šçš„å›¾ç‰‡ä¸Šè‰²æ¨¡å—\n",
    "\n",
    "## AverageMeter(object)\n",
    "è¿™é‡Œç¼–å†™äº†ä¸€ä¸ªè®¡ç®—æ€»å’Œçš„å‡½æ•°ï¼Œä½†æ˜¯æˆ‘ä¸å¤ªç†è§£è¿™ä¸ªå‡½æ•°åœ¨é¡¹ç›®ä¸­çš„ç”¨å¤„.\n",
    "ğŸ‘‰selfå°†classå®šä¹‰ä¸­çš„å˜é‡å’Œå‡½æ•°å˜æˆå®ä¾‹å˜é‡å’Œå®ä¾‹å‡½æ•°ï¼Œä½œä¸ºç±»çš„æˆå‘˜ï¼Œä½¿å¾—æˆå‘˜ä¹‹é—´å°±èƒ½ç›¸äº’è°ƒç”¨ï¼Œä¸éœ€è¦ä»å¤–éƒ¨è°ƒç”¨æ•°æ®å’Œæ–¹æ³•ã€‚å®ç°äº†ä¸€ä¸ªæ•°æ®çš„å°è£…ã€‚"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.val = None\n",
    "        self.avg = None\n",
    "        self.sum = None\n",
    "        self.count = None\n",
    "\n",
    "    def initialize(self, val, weight):\n",
    "        self.val = val\n",
    "        self.avg = val\n",
    "        self.sum = val * weight\n",
    "        self.count = weight\n",
    "        self.initialized = True\n",
    "\n",
    "    def update(self, val, weight=1):\n",
    "        if not self.initialized:\n",
    "            self.initialize(val, weight)\n",
    "        else:\n",
    "            self.add(val, weight)\n",
    "\n",
    "    def add(self, val, weight):\n",
    "        self.val = val\n",
    "        self.sum += val * weight\n",
    "        self.count += weight\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def value(self):\n",
    "        return self.val\n",
    "\n",
    "    def average(self):\n",
    "        return self.avg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## accuracy\n",
    "ä¸€ä¸ªéå¸¸æ™®éçš„accuarcyçš„è¡¡é‡æ–¹æ³•ã€‚å…·ä½“çš„acc scoresæ–‡ç« æœ‰ä¸€ä¸ªç»†è‡´åˆ†ç±»ã€‚"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def accuracy(preds, label):\n",
    "    valid = (label >= 0)\n",
    "    acc_sum = (valid * (preds == label)).sum()\n",
    "    valid_sum = valid.sum()\n",
    "    acc = float(acc_sum) / (valid_sum + 1e-10)\n",
    "    return acc, valid_sum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_38372/2233380055.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrandom\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "a = random([4,4])\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## unique(ar, return_index=False, return_inverse = False)\n",
    "å…·ä½“è¿˜æ²¡æœ‰å˜æ¸…æ¥šæ‹¿æ¥å¹²ä»€ä¹ˆçš„\n",
    "np.asanyarray: å°†énumpyå­˜å‚¨çš„æ•°æ®è¾“å…¥è½¬åŒ–ä¸ºnumpyæ•°æ®å­˜å‚¨å½¢å¼\n",
    "flatten(): return a copy of the array collapsed into one dimension (è¿”å›ä¸€ç»´æ•°æ®)\n",
    "np.empty(shape, dtype): return a new array of given shape and type\n",
    "np.argsort(a, axis): return the indices that would sort an array\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unique(ar, return_index=False, return_inverse=False, return_counts=False):\n",
    "    ar = np.asanyarray(ar).flatten()\n",
    "\n",
    "    optional_indices = return_index or return_inverse\n",
    "    optional_returns = optional_indices or return_counts\n",
    "\n",
    "    if ar.size ==0:\n",
    "        if not optional_returns:\n",
    "            # not return, ret = 0\n",
    "            ret = ar\n",
    "        else:\n",
    "            ret = (ar,)\n",
    "            if return_index:\n",
    "                # return ret, size=0, dtype=bool\n",
    "                ret += (np.empty(0, np.bool),)\n",
    "            if return_inverse:\n",
    "                ret += (np.empty(0, np.bool),)\n",
    "            if return_counts:\n",
    "                ret += (np.empty(0, np.intp),)\n",
    "        return ret\n",
    "    if optional_indices:\n",
    "        perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')\n",
    "        aux = ar[perm]\n",
    "    else:\n",
    "        ar.sort()\n",
    "        aux = ar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## colorEncode\n",
    "torch.astype(): cast a pandas object to a specified dtype.\n",
    "numpy.tile(): å°†colors[label]ä»¥(labelmap.shape[0], labelmap.shape[1],1)çš„å½¢å¼å¹¿æ’­å‡ºæ¥"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def colorEncode(labelmap, colors, mode='BGR'):\n",
    "    labelmap = labelmap.astype('int')\n",
    "    labelmap_rgb = np.zeros((labelmap.shape[0], labelmap.shape[1], 3),\n",
    "                            dtype=np.uint8)\n",
    "    for label in unique(labelmap):\n",
    "        if label < 0:\n",
    "            continue\n",
    "        labelmap_rgb += (labelmap == label)[:, :, np.newaxis] * \\\n",
    "            np.tile(colors[label], (labelmap.shape[0], labelmap.shape[1], 1))\n",
    "\n",
    "    if mode == 'BGR':\n",
    "        return labelmap_rgb[:, :, ::-1]\n",
    "    else:\n",
    "        return labelmap_rgb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}