{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## train流程\n",
    "## upernet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# System libs\n",
    "import os\n",
    "import time\n",
    "# import math\n",
    "import random\n",
    "# Numerical libs\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 创建保存点\n",
    "这里是每一个epoch一个保存点，首先载入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def checkpoint(nets, history, args, epoch_num):\n",
    "    print('Saving checkpoints')\n",
    "    (net_encoder, net_decoder) = nets\n",
    "    suffix_latest = 'epoch_{}.pth'.format(epoch_num)\n",
    "\n",
    "    dict_encoder = net_encoder.state_dict()\n",
    "    dict_decoder = net_decoder.state_dict()\n",
    "\n",
    "    torch.save(history, '{}/history_{}'.format(args.ckpt, suffix_latest))\n",
    "    torch.save(dict_encoder, '{}/encoder_{}'.format(args.ckpt, suffix_latest))\n",
    "    torch.save(dict_decoder, '{}/decoder_{}'.format(args.ckpt, suffix_latest))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 创建"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_optimizers(nets, args):\n",
    "    (net_encoder, net_decoder) = nets\n",
    "    optimizer_encoder = torch.optim.SGD(\n",
    "        group_weight(net_encoder),\n",
    "        lr=args.lr_encoder,\n",
    "        momentum=args.beta1,\n",
    "        weight_decay=args.weight_decay)\n",
    "    optimizer_decoder = torch.optim.SGD(\n",
    "        group_weight(net_decoder),\n",
    "        lr=args.lr_decoder,\n",
    "        momentum=args.beta1,\n",
    "        weight_decay=args.weight_decay)\n",
    "    return (optimizer_encoder, optimizer_decoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## main\n",
    "这里是已经封装好的main代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    builder = ModelBuilder()\n",
    "    # 载入网络结构\n",
    "    net_encoder = builder.build_encoder(\n",
    "        arch = args.arch_encoder,\n",
    "        fc_dim = args.fc_dim,\n",
    "        weights = args.weights_encoder\n",
    "    )\n",
    "    net_decoder = builder.build_encoder(\n",
    "        arch = args.fc_dim,\n",
    "        fc_dim = args.fc_dim,\n",
    "        nr_classes = args.nr_classes,\n",
    "        weights = args.weights_encoder\n",
    "    )\n",
    "\n",
    "    if args.arch_decoder.endswith('deepsup'):\n",
    "        segmentation_module = SegmentationModule(net_encoder, net_decoder, args.deep_sup_scale)\n",
    "    else:\n",
    "        segmentation_module = SegmentationModule(net_encoder, net_decoder)\n",
    "\n",
    "    print('1 Epoch = {} iters'.format(args.epoch_iters))\n",
    "\n",
    "    # create loader iterator\n",
    "    iterator_train = create_multi_source_train_data_loader(args=args)\n",
    "\n",
    "    # load nets into gpu\n",
    "    if args.num_gpus > 1:\n",
    "        segmentation_module = UserScatteredDataParallel(\n",
    "            segmentation_module,\n",
    "            device_ids=range(args.num_gpus))\n",
    "        # For sync bn\n",
    "        patch_replication_callback(segmentation_module)\n",
    "    segmentation_module.cuda()\n",
    "\n",
    "    # Set up optimizers\n",
    "    nets = (net_encoder, net_decoder)\n",
    "    optimizers = create_optimizers(nets, args)\n",
    "\n",
    "    # Main loop\n",
    "    history = {'train': {'epoch': [], 'loss': [], 'acc': []}}\n",
    "\n",
    "    for epoch in range(args.start_epoach, args.num_epoch + 1):\n",
    "        train(segmentation_module, iterator_train, optimizers, history, epoach, args)\n",
    "        checkpoint(nets, history, args, epoch)\n",
    "\n",
    "    print('Training done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}