{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# config 书写形式\n",
    "实际上对于实验的参数来说，有非常多的插入形式。较为普遍的就是整合之后在train函数前作为训练输出。\n",
    "我个人会比较偏爱腾讯挑战赛的编写形式。将代码抽出来作为单独的文件加载。同时，文件中也将参数分为几个小类。\n",
    "\n",
    "## wechat_challenge config\n",
    "整个大文件包含以下的类别\n",
    " - 首先定义文件名称 parser = argparse.ArgumentParser(description=\"Baseline for Weixin Challenge 2022\")\n",
    " - 定义随机数seed\\dropout\n",
    " - 定义数据类型参数train_annotation \\ test_annotation \\ train_zip_feats \\ test_zip_feats \\ test_output_csv \\ val_ratio \\ batch_size \\ val_batch_size \\ test_batch_size \\ prefetch \\ num_workers\n",
    " - 定义保存类型savemodel_path \\ ckpt_file \\ best_score\n",
    " - 定义学习参数max_epochs \\ max_steps \\ print_steps \\ warmup_steps \\ minimum_lr \\ learning_rate \\ weight_decay \\ adam_epsilon\n",
    " - 定义更详细的文件参数，包括Bert \\ video \\ fusion_layer 等，换了新的项目可以使用其他的板子\n",
    " - bert参数包括 bert_dir \\ bert_cache \\ bert_seq_length \\ bert_learning_rate \\ bert_warmup_steps \\ bert_maxup_steps \\ bert_hidden_dropout_prob\n",
    " - video参数包括 frame_embedding_size \\ max_frames \\ vlad_cluster_size \\ vlad_groups \\ vlad_hidden_size \\ se_ratio\n",
    " - fusion_layer包括fc_size\n",
    " 最后return parser.parse_args()\n",
    "\n",
    " 在训练文件中，需要先在头文件from config import parse_args\n",
    " 基础的训练语句有\n",
    " args = parse_args()\n",
    " setup_logging()\n",
    " setup_device(args)\n",
    " setup_seed(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Baseline for Weixin Challenge 2022\")\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int, default=2022, help=\"random seed.\")\n",
    "    parser.add_argument('--dropout', type=float, default=0.3, help='dropout ratio')\n",
    "\n",
    "    # ========================= Data Configs ==========================\n",
    "    parser.add_argument('--train_annotation', type=str, default='C:/wechat_challenge/annotations/labeled_1.json')\n",
    "    parser.add_argument('--test_annotation', type=str, default='C:/wechat_challenge/annotations/test_a.json')\n",
    "    parser.add_argument('--train_zip_feats', type=str, default='C:/wechat_challenge/zip_feats/labeled.zip')\n",
    "    parser.add_argument('--test_zip_feats', type=str, default='C:/wechat_challenge/zip_feats/test_a.zip')\n",
    "    parser.add_argument('--test_output_csv', type=str, default='C:/github/challenge-main/result.csv')\n",
    "    parser.add_argument('--val_ratio', default=0.15, type=float, help='split 10 percentages of training data as validation')\n",
    "    parser.add_argument('--batch_size', default=64, type=int, help=\"use for training duration per worker\")\n",
    "    parser.add_argument('--val_batch_size', default=256, type=int, help=\"use for validation duration per worker\")\n",
    "    parser.add_argument('--test_batch_size', default=256, type=int, help=\"use for testing duration per worker\")\n",
    "    parser.add_argument('--prefetch', default=8, type=int, help=\"use for training duration per worker\")\n",
    "    parser.add_argument('--num_workers', default=4, type=int, help=\"num_workers for dataloaders\")\n",
    "\n",
    "    # ======================== SavedModel Configs =========================\n",
    "    parser.add_argument('--savedmodel_path', type=str, default='C:/github/challenge-main/save/v3')\n",
    "    parser.add_argument('--ckpt_file', type=str, default='C:/github/challenge-main/save/v1/model_epoch_4_mean_f1_0.6127.bin')\n",
    "    parser.add_argument('--best_score', default=0.5, type=float, help='save checkpoint if mean_f1 > best_score')\n",
    "\n",
    "    # ========================= Learning Configs ==========================\n",
    "    parser.add_argument('--max_epochs', type=int, default=20, help='How many epochs')\n",
    "    parser.add_argument('--max_steps', default=50000, type=int, metavar='N', help='number of total epochs to run')\n",
    "    parser.add_argument('--print_steps', type=int, default=20, help=\"Number of steps to log training metrics.\")\n",
    "    parser.add_argument('--warmup_steps', default=1000, type=int, help=\"warm ups for parameters not in bert or vit\")\n",
    "    parser.add_argument('--minimum_lr', default=0., type=float, help='minimum learning rate')\n",
    "    parser.add_argument('--learning_rate', default=5e-5, type=float, help='initial learning rate')\n",
    "    parser.add_argument(\"--weight_decay\", default=0.01, type=float, help=\"Weight deay if we apply some.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-6, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "\n",
    "    # ========================== Title BERT =============================\n",
    "    # parser.add_argument('--bert_dir', type=str, default='hfl/chinese-roberta-wwm-ext-large')\n",
    "    parser.add_argument('--bert_dir', type=str, default='hfl/chinese-macbert-base')\n",
    "    parser.add_argument('--bert_cache', type=str, default='data/cache')\n",
    "    parser.add_argument('--bert_seq_length', type=int, default=80)\n",
    "    parser.add_argument('--bert_learning_rate', type=float, default=3e-5)\n",
    "    parser.add_argument('--bert_warmup_steps', type=int, default=5000)\n",
    "    parser.add_argument('--bert_max_steps', type=int, default=30000)\n",
    "    parser.add_argument(\"--bert_hidden_dropout_prob\", type=float, default=0.1)\n",
    "\n",
    "    # ========================== Video =============================\n",
    "    parser.add_argument('--frame_embedding_size', type=int, default=768)\n",
    "    parser.add_argument('--max_frames', type=int, default=32)\n",
    "    parser.add_argument('--vlad_cluster_size', type=int, default=64)\n",
    "    parser.add_argument('--vlad_groups', type=int, default=8)\n",
    "    parser.add_argument('--vlad_hidden_size', type=int, default=1024, help='nextvlad output size using dense')\n",
    "    parser.add_argument('--se_ratio', type=int, default=8, help='reduction factor in se context gating')\n",
    "\n",
    "    # ========================== Fusion Layer =============================\n",
    "    parser.add_argument('--fc_size', type=int, default=512, help=\"linear size before final linear\")\n",
    "\n",
    "    return parser.parse_args()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## unifiedparsing\n",
    "UperNet采用科研训练代码常用的，将argparse丢进main里面。我认为这个并不是一个很好的书写方式，我个人会坚持将argparse丢进config里面的写法\n",
    "但是这里有一个很好的习惯，就是在输入了超参数之后会跟一个输出。我尝试利用微信挑战赛的方式给这些超参数分一个类。作为semantic segmentation领域超参数的一个参考和汇总。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "    # Model related arguments\n",
    "parser.add_argument('--id', default='baseline',\n",
    "                        help=\"a name for identifying the model\")\n",
    "parser.add_argument('--arch_encoder', default='resnet50',\n",
    "                        help=\"architecture of net_encoder\")\n",
    "parser.add_argument('--arch_decoder', default='upernet',\n",
    "                        help=\"architecture of net_decoder\")\n",
    "parser.add_argument('--weights_encoder', default='',\n",
    "                        help=\"weights to finetune net_encoder\")\n",
    "parser.add_argument('--weights_decoder', default='',\n",
    "                        help=\"weights to finetune net_decoder\")\n",
    "parser.add_argument('--fc_dim', default=2048, type=int,\n",
    "                        help='number of features between encoder and decoder')\n",
    "\n",
    "    # optimization related arguments\n",
    "    parser.add_argument('--num_gpus', default=8, type=int,\n",
    "                        help='number of gpus to use')\n",
    "    parser.add_argument('--batch_size_per_gpu', default=2, type=int,\n",
    "                        help='input batch size')\n",
    "    parser.add_argument('--num_epoch', default=40, type=int,\n",
    "                        help='epochs to train for')\n",
    "    parser.add_argument('--start_epoch', default=1, type=int,\n",
    "                        help='epoch to start training. useful if continue from a checkpoint')\n",
    "    parser.add_argument('--epoch_iters', default=5000, type=int,\n",
    "                        help='iterations of each epoch (irrelevant to batch size)')\n",
    "    parser.add_argument('--optim', default='SGD', help='optimizer')\n",
    "    parser.add_argument('--lr_encoder', default=2e-2, type=float, help='LR')\n",
    "    parser.add_argument('--lr_decoder', default=2e-2, type=float, help='LR')\n",
    "    parser.add_argument('--lr_pow', default=0.9, type=float,\n",
    "                        help='power in poly to drop LR')\n",
    "    parser.add_argument('--beta1', default=0.9, type=float,\n",
    "                        help='momentum for sgd, beta1 for adam')\n",
    "    parser.add_argument('--weight_decay', default=1e-4, type=float,\n",
    "                        help='weights regularizer')\n",
    "    parser.add_argument('--fix_bn', default=0, type=int,\n",
    "                        help='fix bn params')\n",
    "\n",
    "    # Data related arguments\n",
    "    parser.add_argument('--workers', default=16, type=int,\n",
    "                        help='number of data loading workers')\n",
    "    parser.add_argument('--imgSize', default=[300,375,450,525,600], nargs='+', type=int,\n",
    "                        help='input image size of short edge (int or list)')\n",
    "    parser.add_argument('--imgMaxSize', default=1000, type=int,\n",
    "                        help='maximum input image size of long edge')\n",
    "    parser.add_argument('--padding_constant', default=32, type=int,\n",
    "                        help='maxmimum downsampling rate of the network')\n",
    "    parser.add_argument('--segm_downsampling_rate', default=4, type=int,\n",
    "                        help='downsampling rate of the segmentation label')\n",
    "    parser.add_argument('--random_flip', default=True, type=bool,\n",
    "                        help='if horizontally flip images when training')\n",
    "\n",
    "# saving model configs\n",
    "parser.add_argument('--seed', default=304, type=int, help='manual seed')\n",
    "parser.add_argument('--ckpt', default='./ckpt',\n",
    "                        help='folder to output checkpoints')\n",
    "parser.add_argument('--disp_iter', type=int, default=20,\n",
    "                        help='frequency to display')\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(\"Input arguments:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}