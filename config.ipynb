{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# config 书写形式\n",
    "实际上对于实验的参数来说，有非常多的插入形式。较为普遍的就是整合之后在train函数前作为训练输出。\n",
    "我个人会比较偏爱腾讯挑战赛的编写形式。将代码抽出来作为单独的文件加载。同时，文件中也将参数分为几个小类。\n",
    "\n",
    "## wechat_challenge config\n",
    "整个大文件包含以下的类别\n",
    " - 首先定义文件名称 parser = argparse.ArgumentParser(description=\"Baseline for Weixin Challenge 2022\")\n",
    " - 定义随机数seed\\dropout\n",
    " - 定义数据类型参数train_annotation \\ test_annotation \\ train_zip_feats \\ test_zip_feats \\ test_output_csv \\ val_ratio \\ batch_size \\ val_batch_size \\ test_batch_size \\ prefetch \\ num_workers\n",
    " - 定义保存类型savemodel_path \\ ckpt_file \\ best_score\n",
    " - 定义学习参数max_epochs \\ max_steps \\ print_steps \\ warmup_steps \\ minimum_lr \\ learning_rate \\ weight_decay \\ adam_epsilon\n",
    " - 定义更详细的文件参数，包括Bert \\ video \\ fusion_layer 等，换了新的项目可以使用其他的板子\n",
    " - bert参数包括 bert_dir \\ bert_cache \\ bert_seq_length \\ bert_learning_rate \\ bert_warmup_steps \\ bert_maxup_steps \\ bert_hidden_dropout_prob\n",
    " - video参数包括 frame_embedding_size \\ max_frames \\ vlad_cluster_size \\ vlad_groups \\ vlad_hidden_size \\ se_ratio\n",
    " - fusion_layer包括fc_size\n",
    " 最后return parser.parse_args()\n",
    "\n",
    " 在训练文件中，需要先在头文件from config import parse_args\n",
    " 基础的训练语句有\n",
    " args = parse_args()\n",
    " setup_logging()\n",
    " setup_device(args)\n",
    " setup_seed(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Baseline for Weixin Challenge 2022\")\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int, default=2022, help=\"random seed.\")\n",
    "    parser.add_argument('--dropout', type=float, default=0.3, help='dropout ratio')\n",
    "\n",
    "    # ========================= Data Configs ==========================\n",
    "    parser.add_argument('--train_annotation', type=str, default='C:/wechat_challenge/annotations/labeled_1.json')\n",
    "    parser.add_argument('--test_annotation', type=str, default='C:/wechat_challenge/annotations/test_a.json')\n",
    "    parser.add_argument('--train_zip_feats', type=str, default='C:/wechat_challenge/zip_feats/labeled.zip')\n",
    "    parser.add_argument('--test_zip_feats', type=str, default='C:/wechat_challenge/zip_feats/test_a.zip')\n",
    "    parser.add_argument('--test_output_csv', type=str, default='C:/github/challenge-main/result.csv')\n",
    "    parser.add_argument('--val_ratio', default=0.15, type=float, help='split 10 percentages of training data as validation')\n",
    "    parser.add_argument('--batch_size', default=64, type=int, help=\"use for training duration per worker\")\n",
    "    parser.add_argument('--val_batch_size', default=256, type=int, help=\"use for validation duration per worker\")\n",
    "    parser.add_argument('--test_batch_size', default=256, type=int, help=\"use for testing duration per worker\")\n",
    "    parser.add_argument('--prefetch', default=8, type=int, help=\"use for training duration per worker\")\n",
    "    parser.add_argument('--num_workers', default=4, type=int, help=\"num_workers for dataloaders\")\n",
    "\n",
    "    # ======================== SavedModel Configs =========================\n",
    "    parser.add_argument('--savedmodel_path', type=str, default='C:/github/challenge-main/save/v3')\n",
    "    parser.add_argument('--ckpt_file', type=str, default='C:/github/challenge-main/save/v1/model_epoch_4_mean_f1_0.6127.bin')\n",
    "    parser.add_argument('--best_score', default=0.5, type=float, help='save checkpoint if mean_f1 > best_score')\n",
    "\n",
    "    # ========================= Learning Configs ==========================\n",
    "    parser.add_argument('--max_epochs', type=int, default=20, help='How many epochs')\n",
    "    parser.add_argument('--max_steps', default=50000, type=int, metavar='N', help='number of total epochs to run')\n",
    "    parser.add_argument('--print_steps', type=int, default=20, help=\"Number of steps to log training metrics.\")\n",
    "    parser.add_argument('--warmup_steps', default=1000, type=int, help=\"warm ups for parameters not in bert or vit\")\n",
    "    parser.add_argument('--minimum_lr', default=0., type=float, help='minimum learning rate')\n",
    "    parser.add_argument('--learning_rate', default=5e-5, type=float, help='initial learning rate')\n",
    "    parser.add_argument(\"--weight_decay\", default=0.01, type=float, help=\"Weight deay if we apply some.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-6, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "\n",
    "    # ========================== Title BERT =============================\n",
    "    # parser.add_argument('--bert_dir', type=str, default='hfl/chinese-roberta-wwm-ext-large')\n",
    "    parser.add_argument('--bert_dir', type=str, default='hfl/chinese-macbert-base')\n",
    "    parser.add_argument('--bert_cache', type=str, default='data/cache')\n",
    "    parser.add_argument('--bert_seq_length', type=int, default=80)\n",
    "    parser.add_argument('--bert_learning_rate', type=float, default=3e-5)\n",
    "    parser.add_argument('--bert_warmup_steps', type=int, default=5000)\n",
    "    parser.add_argument('--bert_max_steps', type=int, default=30000)\n",
    "    parser.add_argument(\"--bert_hidden_dropout_prob\", type=float, default=0.1)\n",
    "\n",
    "    # ========================== Video =============================\n",
    "    parser.add_argument('--frame_embedding_size', type=int, default=768)\n",
    "    parser.add_argument('--max_frames', type=int, default=32)\n",
    "    parser.add_argument('--vlad_cluster_size', type=int, default=64)\n",
    "    parser.add_argument('--vlad_groups', type=int, default=8)\n",
    "    parser.add_argument('--vlad_hidden_size', type=int, default=1024, help='nextvlad output size using dense')\n",
    "    parser.add_argument('--se_ratio', type=int, default=8, help='reduction factor in se context gating')\n",
    "\n",
    "    # ========================== Fusion Layer =============================\n",
    "    parser.add_argument('--fc_size', type=int, default=512, help=\"linear size before final linear\")\n",
    "\n",
    "    return parser.parse_args()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}