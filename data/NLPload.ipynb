{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CLIP中文字数据的加载"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20872/4191068118.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mtrasformer_heads\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mtransformer_layer\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mvocab_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvocab_size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;31m# 初始化传入数据\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "# 传入参数\n",
    "vocab_size : int\n",
    "context_length : int\n",
    "transformer_width : int\n",
    "trasformer_heads : int\n",
    "transformer_layer : int\n",
    "vocab_size = vocab_size\n",
    "\n",
    "# 初始化传入数据\n",
    "context_length = context_length\n",
    "vocab_size = vocab_size\n",
    "token_embedding = nn.Embedding(vocab_size, transformer_width)\n",
    "positional_embedding = nn.Parameter(torch.empty(context_length, transformer_width))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### dtype函数及具体的使用\n",
    "dtype函数在这里会返回图像部分第一层卷积的weight权重数据\n",
    "在这里dtype函数的用法更像固定调用，会固定调用出某层的数据类型\n",
    "\n",
    "### type()函数用法\n",
    "如果只有第一个参数则返回回想的类型， 三个参数会返回新的类型对象"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@property\n",
    "def dtype(self):\n",
    "    return self.visual.conv1.weight.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### text处理中transformer的应用\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_attention_mask():\n",
    "    # initialize square\n",
    "    mask = torch.empty(context_length, context_length)\n",
    "    mask.fill_(float(\"-inf\"))\n",
    "    mask.triu_(1) # zero out the lowe diagonal\n",
    "    return mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, width:int,\n",
    "                 layers:int,\n",
    "                 heads:int,\n",
    "                 attn_mask: torch.Tensor=build_attention_mask):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "        self.layers = layers\n",
    "        self.resblocks = nn.Sequential(*[ResidualAttentionBlock(width, heads, attn_mask) for _ in range[layers]])\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.resblocks(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LayerNorm层的应用"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LayerNorm(nn.LayerNorm):\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        orig_type = x.dtype\n",
    "        ret = super().forward(x.type(torch.float32))\n",
    "        return ret.type(orig_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### torch.arange 以及 torch.argmax\n",
    "torch.argmax会输出矩阵最大值\n",
    "torch.arange会输出给定步长的值\n",
    "torch.arange(x.shape[0])会返回从[0,shape[0])的数组，默认步长为1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    width=transformer_width,\n",
    "    layers = transformer_layer,\n",
    "    heads = trasformer_heads,\n",
    "    attn_mask = None\n",
    ")\n",
    "\n",
    "ln_final = LayerNorm(transformer_width)\n",
    "text_projection = nn.Parameter(torch.empty(context_length, transformer_width))\n",
    "\n",
    "def encode_text(text):\n",
    "    x = token_embedding(text).type(dtype) #[batch_size, n_ctx, d_model]\n",
    "    x = x + positional_embedding.type(dtype)\n",
    "    x = x.permute(1, 0, 2) # NLD -> LND\n",
    "    x = transformer(x)\n",
    "    x = x.permute(1, 0, 2) # LND -> NLD\n",
    "    x = ln_final(x).type(dtype)\n",
    "\n",
    "    # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "    # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "    x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ text_projection\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### clip中图像数据的加载\n",
    "clip以resnet和transformer分别作为主干网络，在这里我们使用resnet作为参考"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 初始化\n",
    "embed_dim: int\n",
    "image_resolution: int\n",
    "vision_layers: Union[Tuple[int, int, int, int], int]\n",
    "vision_width: int\n",
    "vision_patch_size: int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ModifiedResNet(nn.Module):\n",
    "    def __init__(self, layers, output_dim, heads, input_resolution=224, width=64):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.input_resolution = input_resolution\n",
    "\n",
    "        self.conv1 = nn.Conv2d()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vision_heads = vision_width * 32 // 64\n",
    "visual = ModifiedResNet(\n",
    "    layers = vision_layers,\n",
    "    output_dim = embed_dim,\n",
    "    heads = vision_heads,\n",
    "    input_resolution = image_resolution,\n",
    "    width = vision_width\n",
    ")\n",
    "\n",
    "def encode_imag(self, image):\n",
    "    return self.visual(image.type(dtype))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}